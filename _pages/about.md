---
permalink: /
title: "About Me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

Hi everyone! Iâ€™m **Hang Yu (Demo)** â€” thank you for visiting my homepage.  
I received my **Bachelorâ€™s degree in Computer Science** from the **University of Macau**, where I completed my undergraduate thesis under **Prof. Jiantao Zhou**. I later earned my **Masterâ€™s degree in Robotics and Autonomous Systems** from **Boston University**.

ðŸ“§ **Contact:** [demoyu@bu.edu](mailto:demoyu@bu.edu) | [yh974125@gmail.com](mailto:yh974125@gmail.com)

---

### ðŸ§  Research Interests

My research lies at the intersection of **computer vision**, **generative AI** **robot learning**, and **Embodied AI**, with the goal of building intelligent systems that can *see, reason, and act* in the physical world.  

I am particularly interested in:
1. **Learning from Video for Robotic Control** â€“ leveraging large-scale video data to teach robots visuomotor skills and motion imitation.  
2. **Video Generation and Visual World Modeling** â€“ developing generative models (e.g., diffusion and transformer architectures) to simulate and predict physical interactions.  
3. **Multi-Robot Collaboration** â€“ enabling coordinated behaviors across humanoid, quadruped, and manipulator systems through communication and shared policy learning.  
4. **Embodied and Vision-Language-Action (VLA) Models** â€“ integrating perception, language, and action for generalizable embodied reasoning.  

[[WeChat](/images/wechat.jpg)] / [[CV](/assets/Resume.pdf)]

---

### ðŸ’¼ Research Experience

**Research Assistant, Hong Kong University of Science and Technology (Guangzhou Campus)**  
*May 2025 â€“ Present*  
Working under **Prof. Haoang Li** on **Embodied AI** and **video generation**, exploring how visual world modeling and action grounding can enhance robot perception and generalization.

**Research Assistant, Guangdong Institute of Intelligent Science and Technology**  
*May â€“ Aug 2024*  
Worked in the **Lab of Brain-Inspired Open-World Intelligence Computing** under **Dr. Chaoran Yang**, integrating **Spiking Neural Networks (SNNs)** into diffusion-based visuomotor policies to improve biological plausibility, temporal dynamics, and energy efficiency in robotic manipulation.

---

### ðŸ’¼ Research Experience

**Robotics Software Engineer, Autel Robotics (Shenzhen, China)**  
*Feb â€“ May 2025*  
Developed and optimized **quadruped robot simulation environments** using **Isaac Lab**, ensuring accurate physics modeling and sensor integration. Designed **reinforcement learning (RL)** pipelines for quadruped locomotion with **Isaac Gym**, tuning reward functions and policies for robust gait generation. Implemented **SLAM** and **autonomous navigation** with the **ROS2 Nav2** stack, enabling terrain-aware mapping and path planning in dynamic environments.

